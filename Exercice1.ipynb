{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPIp8TFQSyUTlfwdUIgLC1N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agbamate1/Batch-project/blob/main/Exercice1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## introduction-to-machine-learning"
      ],
      "metadata": {
        "id": "KU6VAc4kOk-2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise: Using a Trained Model on New Data"
      ],
      "metadata": {
        "id": "gReNI-fOODTL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1-Create a basic model.**\n",
        "\n",
        "**2-Save it to disk.**\n",
        "\n",
        "**3-Load it from disk.**\n",
        "\n",
        "**4-Use it to make predictions about a dog who was not in the training dataset.**"
      ],
      "metadata": {
        "id": "YPY_jkM3OMNk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# encore une methode de charger les données avec VSCode\n",
        "import pandas as pd\n",
        "import requests as rq\n",
        "url_graphing=\"https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/graphing.py\"\n",
        "response=rq.get(url_graphing)\n",
        "\n",
        "with open(\"graphing.py\",\"w\") as file:\n",
        "  file.write(response.text)\n",
        "\n",
        "url_dataset=\"https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/doggy-boot-harness.csv\"\n",
        "response=rq.get(url_dataset)\n",
        "\n",
        "with open (\"doggy-boot-harness.csv\",\"wb\") as file: # telecharger en mode binaire\n",
        "  file.write(response.content)\n",
        "\n",
        "df=pd.read_csv(\"doggy-boot-harness.csv\")\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hELIm3o_PoKN",
        "outputId": "3377be96-b3b5-46c9-b1dd-dabf4aa81320"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   boot_size  harness_size     sex  age_years\n",
            "0         39            58    male       12.0\n",
            "1         38            58    male        9.6\n",
            "2         37            52  female        8.6\n",
            "3         39            58    male       10.2\n",
            "4         38            57    male        7.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_6M_FY0Nsei",
        "outputId": "4bf7429e-84fd-4717-c3d9-d23397b7201f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (0.14.4)\n",
            "Requirement already satisfied: numpy<3,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (1.26.4)\n",
            "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (1.13.1)\n",
            "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (1.0.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.17.0)\n",
            "--2025-01-02 13:37:03--  https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/graphing.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21511 (21K) [text/plain]\n",
            "Saving to: ‘graphing.py.1’\n",
            "\n",
            "graphing.py.1       100%[===================>]  21.01K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2025-01-02 13:37:03 (24.6 MB/s) - ‘graphing.py.1’ saved [21511/21511]\n",
            "\n",
            "--2025-01-02 13:37:03--  https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/doggy-boot-harness.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 838 [text/plain]\n",
            "Saving to: ‘doggy-boot-harness.csv.1’\n",
            "\n",
            "doggy-boot-harness. 100%[===================>]     838  --.-KB/s    in 0s      \n",
            "\n",
            "2025-01-02 13:37:04 (49.6 MB/s) - ‘doggy-boot-harness.csv.1’ saved [838/838]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Deuxieme maniere simple de charger les données en colab\n",
        "import pandas as pd\n",
        "!pip install statsmodels\n",
        "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/graphing.py\n",
        "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/doggy-boot-harness.csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"doggy-boot-harness.csv\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOMxjdYpO534",
        "outputId": "d27d7606-772b-4acc-ad9d-5a5a2965e057"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   boot_size  harness_size     sex  age_years\n",
            "0         39            58    male       12.0\n",
            "1         38            58    male        9.6\n",
            "2         37            52  female        8.6\n",
            "3         39            58    male       10.2\n",
            "4         38            57    male        7.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create and train a model**"
      ],
      "metadata": {
        "id": "DUW0x8KCTMe7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.formula.api as smf\n",
        "\n",
        "formula=\"boot_size~harness_size\"\n",
        "\n",
        "regression=smf.ols(formula=formula, data=df)\n",
        "model=regression.fit()\n",
        "\n",
        "print(\"Model est entrainé\")\n",
        "\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhUWnrPiTRgD",
        "outputId": "2bd24bf2-5dcd-4df4-9589-b5275ae6e992"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model est entrainé\n",
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:              boot_size   R-squared:                       0.569\n",
            "Model:                            OLS   Adj. R-squared:                  0.560\n",
            "Method:                 Least Squares   F-statistic:                     63.37\n",
            "Date:                Thu, 02 Jan 2025   Prob (F-statistic):           2.53e-10\n",
            "Time:                        15:34:46   Log-Likelihood:                -93.054\n",
            "No. Observations:                  50   AIC:                             190.1\n",
            "Df Residuals:                      48   BIC:                             193.9\n",
            "Df Model:                           1                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "================================================================================\n",
            "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
            "--------------------------------------------------------------------------------\n",
            "Intercept        5.7191      4.102      1.394      0.170      -2.528      13.966\n",
            "harness_size     0.5859      0.074      7.960      0.000       0.438       0.734\n",
            "==============================================================================\n",
            "Omnibus:                        2.715   Durbin-Watson:                   1.717\n",
            "Prob(Omnibus):                  0.257   Jarque-Bera (JB):                1.758\n",
            "Skew:                           0.228   Prob(JB):                        0.415\n",
            "Kurtosis:                       2.203   Cond. No.                     1.02e+03\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The condition number is large, 1.02e+03. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save and load a model**"
      ],
      "metadata": {
        "id": "N5eCAgwLUjrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# votre model est pret mais n'est pas encore sauvegardé sur votre disck\n",
        "import joblib\n",
        "model_filename=\"./mode_doggy_boot_harness.pkl\"\n",
        "joblib.dump(model,model_filename)\n",
        "\n",
        "print(\"Model est sauvegardé!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJvQYaf1Ur-8",
        "outputId": "de43a881-fc33-4f73-ce72-39f1e9938d34"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model est sauvegardé!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test Télécharge ton model**"
      ],
      "metadata": {
        "id": "rR4KvjbjV2FF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Telechargeons notre Model\n",
        "\n",
        "model_loaded=joblib.load(model_filename)\n",
        "print(\"Nous venons de télécharger notre model avec ces parametres:\")\n",
        "print(model_loaded.params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8HwL4-VV-CE",
        "outputId": "8619ad35-8e86-4afc-8d55-19ed30d0484a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nous venons de télécharger notre model avec ces parametres:\n",
            "Intercept       5.719110\n",
            "harness_size    0.585925\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Put it together**\n",
        "\n",
        "On our website, we want to take the harness of our customer's dog, then calculate their dog's boot size using the model that we've already trained.\n",
        "Let's put everything here together to make a function that loads the model from disk, then uses it to predict our customer's dog's boot size."
      ],
      "metadata": {
        "id": "RpwIsWciW6cb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "def load_model_predict(harness_size):\n",
        "  \"\"\" En premier temps nous allons telechargé le model sur notre disck\n",
        "      et connaitre les parametre de notre model entrainé et puis\n",
        "      nous allons fait une prediction sur le cm de la chaussure du Chien (boot-Dog)\n",
        "\n",
        "  \"\"\"\n",
        "  load_model=joblib.load(model_filename)\n",
        "  print(f\"Les parametres du Model sont:\\n{load_model.params}\")\n",
        "\n",
        "  #etablissons la prediction\n",
        "  harness_size_pred={\"harness_size\":[harness_size]}\n",
        "\n",
        "  prediction=model.predict(harness_size_pred)[0]\n",
        "\n",
        "  return prediction\n",
        "\n",
        "test=load_model_predict(45)\n",
        "\n",
        "print(f\"La prediction de harness_size est: {round(test,0)} cm\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxaO8l5VXE3M",
        "outputId": "37a506f4-b486-4495-d336-2b87ea50e2fe"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Les parametres du Model sont:\n",
            "Intercept       5.719110\n",
            "harness_size    0.585925\n",
            "dtype: float64\n",
            "La prediction de harness_size est: 32.0 cm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Real World Use"
      ],
      "metadata": {
        "id": "Ivktkootk5g9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "def check_size_boots(select_harness_size,select_boots_size):\n",
        "  \"\"\"\n",
        "  Le but de cette fonction est de permettre aux client de faire une bonne selection\n",
        "  du pointure de la chaussure de leur chien avalanche (boot_size).\n",
        "  Si une mauvause selection est fait, c'est à dire si la pointure de la\n",
        "  chausure selectionnée n'est pas celle que le model entrainé estime, alors un méssage doit etre\n",
        "  envoié au client pour leur notifié que leur choix doit etre modifié (gros ou petit par\n",
        "  rapport à l'estimation du model)\n",
        "  \"\"\"\n",
        "  model_filename=\"./mode_doggy_boot_harness.pkl\"\n",
        "  model_load=joblib.load(model_filename)\n",
        "  model_predict=model_load.predict({\"harness_size\":[select_harness_size]})\n",
        "  boot_estimé=round(model_predict[0],0)\n",
        "\n",
        "  print(f\"Le boot estimé est:{boot_estimé}\")\n",
        "\n",
        "  # condition de comparaison avec le boot estimé\n",
        "\n",
        "  if select_boots_size==boot_estimé:\n",
        "    print(\"La chaussure de votre chien avalance selectionnée est conforme:\")\n",
        "  elif select_boots_size<boot_estimé:\n",
        "    print(f\"La chaussure de votre chien avalance selectionnée est trop petite à: {boot_estimé}\")\n",
        "  else:\n",
        "    print(f\"La chaussure de votre chien avalance selectionnée est trop grande à: {boot_estimé}\")\n",
        "\n",
        "\n",
        "check_size_boots(select_harness_size=45,select_boots_size=40)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhYHXr0hk4c0",
        "outputId": "66d757b1-5739-412c-a13f-0bb68392823a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Le boot estimé est:32.0\n",
            "La chaussure de votre chien avalance selectionnée est trop grande à: 32.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neuer Abschnitt"
      ],
      "metadata": {
        "id": "AVyVBCB8Ih-q"
      }
    }
  ]
}